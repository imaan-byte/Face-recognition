{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import threading \n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA HANDELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 images belonging to 3 classes.\n",
      "Found 45 images belonging to 3 classes.\n",
      "Found 45 images belonging to 3 classes.\n",
      "Class mappings: {'Denzel': 0, 'Imaan': 1, 'Sandra': 2}\n",
      "Training samples: 210\n",
      "Validation samples: 45\n",
      "Test samples: 45\n"
     ]
    }
   ],
   "source": [
    "# data_handling.py\n",
    "from libs import tf  # Import TensorFlow from libs.py\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_data_generator(directory, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=True, augment=False):\n",
    "    \"\"\"\n",
    "    Create and return a data generator using ImageDataGenerator and flow_from_directory.\n",
    "\n",
    "    Args:\n",
    "    - directory: Path to the directory containing subdirectories for each class.\n",
    "    - target_size: Tuple (height, width) to resize the images.\n",
    "    - batch_size: Number of images per batch.\n",
    "    - class_mode: 'categorical' (default) for one-hot encoding.\n",
    "    - shuffle: Whether to shuffle the data (True for training, False for validation/test).\n",
    "    - augment: Whether to apply data augmentation (True for training, False for validation/test).\n",
    "\n",
    "    Returns:\n",
    "    - A data generator instance.\n",
    "    \"\"\"\n",
    "    if augment:\n",
    "        # Data augmentation for training\n",
    "        datagen = ImageDataGenerator(\n",
    "            rescale=1./255,         # Normalize pixel values to [0, 1]\n",
    "            rotation_range=30,      # Random rotation\n",
    "            width_shift_range=0.2,  # Horizontal shift\n",
    "            height_shift_range=0.2, # Vertical shift\n",
    "            shear_range=0.2,        # Shearing\n",
    "            zoom_range=0.2,         # Random zoom\n",
    "            horizontal_flip=True,   # Horizontal flip\n",
    "            fill_mode='nearest'     # Fill mode for augmented pixels\n",
    "        )\n",
    "    else:\n",
    "        # Only rescale for validation and testing\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Create the data generator\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory=directory,\n",
    "        target_size=target_size,   # Resize images to the target size\n",
    "        batch_size=batch_size,    # Number of images per batch\n",
    "        class_mode=class_mode,    # One-hot encoding for multi-class classification\n",
    "        shuffle=shuffle           # Shuffle for training; no shuffle for validation/test\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "def load_data(train_dir, val_dir, test_dir, target_size=(224, 224), batch_size=32):\n",
    "    \"\"\"\n",
    "    Load and return the training, validation, and test data generators.\n",
    "\n",
    "    Args:\n",
    "    - train_dir: Path to the training dataset directory.\n",
    "    - val_dir: Path to the validation dataset directory.\n",
    "    - test_dir: Path to the test dataset directory.\n",
    "    - target_size: Tuple (height, width) to resize the images.\n",
    "    - batch_size: Number of images per batch.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple of (train_generator, val_generator, test_generator).\n",
    "    \"\"\"\n",
    "    # Training data generator with augmentation\n",
    "    train_generator = create_data_generator(\n",
    "        directory=train_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,  # Shuffle training data\n",
    "        augment=True   # Apply augmentation\n",
    "    )\n",
    "\n",
    "    # Validation data generator without augmentation\n",
    "    val_generator = create_data_generator(\n",
    "        directory=val_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,  # Do not shuffle validation data\n",
    "        augment=False   # No augmentation\n",
    "    )\n",
    "\n",
    "    # Test data generator without augmentation\n",
    "    test_generator = create_data_generator(\n",
    "        directory=test_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,  # Do not shuffle test data\n",
    "        augment=False   # No augmentation\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "# If running this script directly, test the data generators\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace these paths with the actual dataset directories\n",
    "    train_dir = 'faces_folder/train'\n",
    "    val_dir = 'faces_folder/validation'\n",
    "    test_dir = 'faces_folder/test'\n",
    "\n",
    "    # Load data generators\n",
    "    train_gen, val_gen, test_gen = load_data(train_dir, val_dir, test_dir)\n",
    "\n",
    "    # Print class indices for verification\n",
    "    print(\"Class mappings:\", train_gen.class_indices)\n",
    "\n",
    "    # Print some details about the datasets\n",
    "    print(f\"Training samples: {train_gen.samples}\")\n",
    "    print(f\"Validation samples: {val_gen.samples}\")\n",
    "    print(f\"Test samples: {test_gen.samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 images belonging to 3 classes.\n",
      "Found 45 images belonging to 3 classes.\n",
      "Found 45 images belonging to 3 classes.\n",
      "Class mappings: {'Denzel': 0, 'Imaan': 1, 'Sandra': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 8s/step - accuracy: 0.5406 - loss: 1.8384 - val_accuracy: 0.6667 - val_loss: 0.8003\n",
      "Epoch 2/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5s/step - accuracy: 0.8202 - loss: 0.7251 - val_accuracy: 0.9111 - val_loss: 0.3249\n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.9291 - loss: 0.1832 - val_accuracy: 0.9556 - val_loss: 0.1824\n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8s/step - accuracy: 0.9582 - loss: 0.2171 - val_accuracy: 0.9556 - val_loss: 0.0944\n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5s/step - accuracy: 0.9775 - loss: 0.0683 - val_accuracy: 0.9778 - val_loss: 0.1089\n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5s/step - accuracy: 0.9552 - loss: 0.1004 - val_accuracy: 0.9333 - val_loss: 0.1271\n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5s/step - accuracy: 0.9671 - loss: 0.1067 - val_accuracy: 0.9333 - val_loss: 0.1250\n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5s/step - accuracy: 0.9614 - loss: 0.1352 - val_accuracy: 0.9333 - val_loss: 0.1919\n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.9814 - loss: 0.0690 - val_accuracy: 0.9556 - val_loss: 0.0915\n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5s/step - accuracy: 0.9860 - loss: 0.0531 - val_accuracy: 0.9556 - val_loss: 0.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 'trained_model.h5'\n",
      "history saved\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9495 - loss: 0.1601\n",
      "Test Loss: 0.14100562036037445, Test Accuracy: 0.9555555582046509\n"
     ]
    }
   ],
   "source": [
    "# training.py\n",
    "from model_arc import model_build\n",
    "from data_handling import load_data\n",
    "\n",
    "import pickle\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"\n",
    "    Train the model with training and validation datasets and evaluate it on the test dataset.\n",
    "    \"\"\"\n",
    "    # Dataset directories\n",
    "    train_dir = 'faces_folder/train'\n",
    "    val_dir = 'faces_folder/validation'\n",
    "    test_dir = 'faces_folder/test'\n",
    "\n",
    "    # Load data\n",
    "    train_generator, val_generator, test_generator = load_data(train_dir, val_dir, test_dir)\n",
    "\n",
    "    # Print class mappings for debugging\n",
    "    print(\"Class mappings:\", train_generator.class_indices)\n",
    "\n",
    "    # Build the model\n",
    "    model = model_build()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=val_generator\n",
    "    )\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save('trained_model.h5')\n",
    "    print(\"Model saved to 'trained_model.h5'\")\n",
    "\n",
    "    with open('training_history.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    print(\"history saved\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(test_generator)\n",
    "    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m historypath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_history.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     38\u001b[0m history \u001b[38;5;241m=\u001b[39m load_history\n\u001b[1;32m---> 41\u001b[0m \u001b[43mcreate_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m, in \u001b[0;36mcreate_graph\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_graph\u001b[39m(history):\n\u001b[0;32m     12\u001b[0m     \n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Plot training and validation metrics\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     16\u001b[0m     val_accuracy \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "from libs import tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "def load_history(historypath):\n",
    "    with open(historypath, 'rb')  as f:\n",
    "        history = pickle.load(f)\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Save the model\n",
    "def create_graph(history):\n",
    "    \n",
    "\n",
    "    # Plot training and validation metrics\n",
    "    accuracy = history.model[\"accuracy\"]\n",
    "    val_accuracy = history.model[\"val_accuracy\"]\n",
    "    loss = history.model[\"loss\"]\n",
    "    val_loss = history.model[\"val_loss\"]\n",
    "    epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, accuracy, \"bo-\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_accuracy, \"ro-\", label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, \"bo-\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"ro-\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    historypath = 'training_history.pkl'\n",
    "    history = load_history\n",
    "\n",
    "    \n",
    "    create_graph(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEBCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from libs import tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import threading\n",
    "import time\n",
    "\n",
    "class WebcamFaceRecognition:\n",
    "    def __init__(self, model_path, class_labels):\n",
    "        self.model = load_model(model_path)  # Load the trained model\n",
    "        self.class_labels = class_labels  # Class labels for prediction\n",
    "\n",
    "        # Thread-safe variables\n",
    "        self.frame = None  # Current frame from the webcam\n",
    "        self.predicted_label = \"Loading...\"  # Prediction result\n",
    "        self.running = True  # Flag to control threads\n",
    "\n",
    "        # Initialize the webcam\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        if not self.cap.isOpened():\n",
    "            raise RuntimeError(\"Error: Unable to access the webcam.\")\n",
    "\n",
    "    def preprocess_frame(self, frame, target_size=(224, 224)):\n",
    "        \"\"\"\n",
    "        Preprocess a single frame for model prediction.\n",
    "        \"\"\"\n",
    "        resized_frame = cv2.resize(frame, target_size)  # Resize to model input size\n",
    "        normalized_frame = resized_frame / 255.0  # Normalize pixel values\n",
    "        preprocessed_frame = np.expand_dims(normalized_frame, axis=0)  # Add batch dimension\n",
    "        return preprocessed_frame\n",
    "\n",
    "    def capture_frames(self):\n",
    "        \"\"\"\n",
    "        Capture frames from the webcam in a separate thread.\n",
    "        \"\"\"\n",
    "        while self.running:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Unable to read a frame from the webcam.\")\n",
    "                break\n",
    "            self.frame = cv2.flip(frame, 1)  # Flip horizontally for a mirror effect\n",
    "            time.sleep(0.01)  # Small delay to reduce CPU usage\n",
    "\n",
    "    def predict_frame(self):\n",
    "        \"\"\"\n",
    "        Perform predictions in a separate thread.\n",
    "        \"\"\"\n",
    "        while self.running:\n",
    "            if self.frame is not None:\n",
    "                # Preprocess the current frame\n",
    "                preprocessed_frame = self.preprocess_frame(self.frame)\n",
    "\n",
    "                # Make predictions\n",
    "                predictions = self.model.predict(preprocessed_frame)\n",
    "                predicted_class = np.argmax(predictions[0])  # Get class index\n",
    "                self.predicted_label = f\"{self.class_labels[predicted_class]} ({np.max(predictions[0]) * 100:.2f}%)\"\n",
    "            time.sleep(0.05)  # Adjust sleep for prediction frequency\n",
    "\n",
    "    def display_feed(self):\n",
    "        \"\"\"\n",
    "        Display the webcam feed with predictions in the main thread.\n",
    "        \"\"\"\n",
    "        while self.running:\n",
    "            if self.frame is not None:\n",
    "                # Overlay the prediction result on the frame\n",
    "                cv2.putText(self.frame, f\"Prediction: {self.predicted_label}\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                # Show the frame\n",
    "                cv2.imshow(\"Webcam Face Recognition\", self.frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                self.running = False\n",
    "\n",
    "        # Release resources\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Start the webcam face recognition with multithreading.\n",
    "        \"\"\"\n",
    "        # Start threads for frame capture and prediction\n",
    "        capture_thread = threading.Thread(target=self.capture_frames)\n",
    "        prediction_thread = threading.Thread(target=self.predict_frame)\n",
    "\n",
    "        capture_thread.start()\n",
    "        prediction_thread.start()\n",
    "\n",
    "        # Run the display in the main thread\n",
    "        self.display_feed()\n",
    "\n",
    "        # Wait for threads to finish\n",
    "        capture_thread.join()\n",
    "        prediction_thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the trained model\n",
    "    model_path = \"trained_model.h5\"\n",
    "\n",
    "    # List of class labels (must match the training labels)\n",
    "    class_labels = [\"Imaan\", \"Denzel\", \"Sandra\"]\n",
    "\n",
    "    # Initialize and run the face recognition\n",
    "    recognition_system = WebcamFaceRecognition(model_path, class_labels)\n",
    "    recognition_system.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
